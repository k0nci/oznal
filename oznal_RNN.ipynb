{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oznal-RNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC6VKMvT2Nnw",
        "colab_type": "text"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA_fp9jD0B87",
        "colab_type": "code",
        "outputId": "82e3d4d9-8461-461a-ba6f-0c2940b4f4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# import os\n",
        "# os.chdir('gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LK4xytK6sCm",
        "colab_type": "code",
        "outputId": "a899e624-8adc-4c6e-889f-d5cc8c8b7b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/k0nci/oznal/master/data/mbti_1.csv'\n",
        "\n",
        "raw_data = pd.read_csv(url)\n",
        "raw_data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8675</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>16</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>INFP</td>\n",
              "      <td>Captain phillips|||:happy: nice|||I'm currentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1832</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                                              posts\n",
              "count   8675                                               8675\n",
              "unique    16                                               8675\n",
              "top     INFP  Captain phillips|||:happy: nice|||I'm currentl...\n",
              "freq    1832                                                  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3W0_4I6ttF",
        "colab_type": "code",
        "outputId": "03406e87-ec0b-4c3b-8be4-13ba1d017c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "data = raw_data['posts'].apply(lambda x: pd.Series([y.strip() for y in x.split('|||')])) \\\n",
        "                        .reset_index() \\\n",
        "                        .rename(columns={'index': 'user_id'}) \\\n",
        "                        .merge(raw_data, left_index=True, right_index=True) \\\n",
        "                        .drop(columns=['posts']) \\\n",
        "                        .melt(id_vars=['user_id', 'type'], value_name='post', var_name='post_id') \\\n",
        "                        .dropna(subset=['post']) \\\n",
        "                        .sort_values(by=['user_id', 'post_id']) \\\n",
        "                        .reset_index(drop=True)\n",
        "\n",
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>422845.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4340.423529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2506.825488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4345.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6515.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8674.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             user_id\n",
              "count  422845.000000\n",
              "mean     4340.423529\n",
              "std      2506.825488\n",
              "min         0.000000\n",
              "25%      2165.000000\n",
              "50%      4345.000000\n",
              "75%      6515.000000\n",
              "max      8674.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sAwpmc86y1B",
        "colab_type": "code",
        "outputId": "1b39c888-1694-44af-aa3b-19895b564905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data['I'] = data['type'].apply(lambda x: 1 if x[0] == 'I' else 0)\n",
        "data['E'] = data['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
        "\n",
        "data['N'] = data['type'].apply(lambda x: 1 if x[1] == 'N' else 0)\n",
        "data['S'] = data['type'].apply(lambda x: 1 if x[1] == 'S' else 0)\n",
        "\n",
        "data['T'] = data['type'].apply(lambda x: 1 if x[2] == 'T' else 0)\n",
        "data['F'] = data['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
        "\n",
        "data['J'] = data['type'].apply(lambda x: 1 if x[3] == 'J' else 0)\n",
        "data['P'] = data['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>type</th>\n",
              "      <th>post_id</th>\n",
              "      <th>post</th>\n",
              "      <th>I</th>\n",
              "      <th>E</th>\n",
              "      <th>N</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>F</th>\n",
              "      <th>J</th>\n",
              "      <th>P</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>1</td>\n",
              "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>2</td>\n",
              "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>3</td>\n",
              "      <td>What has been the most life-changing experienc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>4</td>\n",
              "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  type post_id                                               post  \\\n",
              "0        0  INFJ       0        'http://www.youtube.com/watch?v=qsXHcwe3krw   \n",
              "1        0  INFJ       1  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...   \n",
              "2        0  INFJ       2  enfp and intj moments  https://www.youtube.com...   \n",
              "3        0  INFJ       3  What has been the most life-changing experienc...   \n",
              "4        0  INFJ       4  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...   \n",
              "\n",
              "   I  E  N  S  T  F  J  P  \n",
              "0  1  0  1  0  0  1  1  0  \n",
              "1  1  0  1  0  0  1  1  0  \n",
              "2  1  0  1  0  0  1  1  0  \n",
              "3  1  0  1  0  0  1  1  0  \n",
              "4  1  0  1  0  0  1  1  0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0AxmkgR7UT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['urls_count'] = data['post'].apply(lambda x: len(re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', x)))\n",
        "\n",
        "data['words_count'] = data['post'].apply(lambda x: len(x.split()))\n",
        "data['sentences_count'] = data['post'].apply(lambda x: len(sent_tokenize(x)))\n",
        "data['words_per_sentence'] = data['words_count'] / data['sentences_count']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pike53EjAM2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['post'] = data['post'].apply(lambda x: x.lower().strip())\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\" +\", \" \", x))\n",
        "\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"/[-\\/\\\\^$*+?.()|[\\]{}]/g\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"[iex\\*][nsx\\*][ftx\\*][pjx\\*]\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"[0-9]+\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"#[a-zA-Z]+\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"['\\\";:,.?!\\/\\\\()\\[\\]+]\", \"\", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\"[-_]\", \" \", x))\n",
        "data['post'] = data['post'].apply(lambda x: re.sub(r\" +\", \" \", x))\n",
        "\n",
        "data = data[data['post'] != '']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWpKlAppL8XC",
        "colab_type": "code",
        "outputId": "a761f906-bd78-4f91-e312-1d37214b7dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "def merge_post(series, sep=' '):\n",
        "  return series.str.cat(sep=sep)\n",
        "\n",
        "user_data = data.groupby('user_id').agg({\n",
        "    'I': 'max',\n",
        "    'post': merge_post,\n",
        "    'words_count': ['mean', 'var'],\n",
        "    'sentences_count': 'mean'\n",
        "})\n",
        "\n",
        "user_data.columns = [\"_\".join(y) for y in user_data.columns.ravel()]\n",
        "\n",
        "user_data.rename(\n",
        "    inplace=True,\n",
        "    columns={\n",
        "        'I_max': 'I',\n",
        "        'post_merge_post': 'posts',\n",
        "        'words_count_mean': 'words_per_post',\n",
        "        'sentences_count_mean': 'sentences_per_post'\n",
        "    }    \n",
        ")\n",
        "\n",
        "\n",
        "user_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>I</th>\n",
              "      <th>posts</th>\n",
              "      <th>words_per_post</th>\n",
              "      <th>words_count_var</th>\n",
              "      <th>sentences_per_post</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>and moments sportscenter not top ten plays pr...</td>\n",
              "      <td>16.416667</td>\n",
              "      <td>124.821429</td>\n",
              "      <td>1.638889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>im finding the lack of me in these posts very ...</td>\n",
              "      <td>25.872340</td>\n",
              "      <td>165.852914</td>\n",
              "      <td>2.723404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>good one  of course to which i say i know that...</td>\n",
              "      <td>20.880952</td>\n",
              "      <td>155.570848</td>\n",
              "      <td>1.976190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>dear i enjoyed our conversation the other day ...</td>\n",
              "      <td>22.260000</td>\n",
              "      <td>185.543265</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>youre fired thats another silly misconception ...</td>\n",
              "      <td>21.553191</td>\n",
              "      <td>187.643848</td>\n",
              "      <td>2.382979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         I                                              posts  words_per_post  \\\n",
              "user_id                                                                         \n",
              "0        1   and moments sportscenter not top ten plays pr...       16.416667   \n",
              "1        0  im finding the lack of me in these posts very ...       25.872340   \n",
              "2        1  good one  of course to which i say i know that...       20.880952   \n",
              "3        1  dear i enjoyed our conversation the other day ...       22.260000   \n",
              "4        0  youre fired thats another silly misconception ...       21.553191   \n",
              "\n",
              "         words_count_var  sentences_per_post  \n",
              "user_id                                       \n",
              "0             124.821429            1.638889  \n",
              "1             165.852914            2.723404  \n",
              "2             155.570848            1.976190  \n",
              "3             185.543265            2.300000  \n",
              "4             187.643848            2.382979  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b1ukLcrCXdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "y = user_data['I']\n",
        "X = user_data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "df_majority = X_train[X_train['I']==1]\n",
        "df_minority = X_train[X_train['I']==0]\n",
        " \n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     \n",
        "                                 n_samples=X_train[X_train['I']==1].shape[0],    \n",
        "                                 random_state=123) \n",
        " \n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "X_train = df_upsampled\n",
        "\n",
        "y_train = X_train['I']\n",
        "\n",
        "X_train = X_train.drop(columns='I')\n",
        "X_test = X_test.drop(columns='I')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYwea6UoBznN",
        "colab_type": "code",
        "outputId": "21aa6613-afa1-4b18-d872-dbea2533ba68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1980
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>words_per_post</th>\n",
              "      <th>words_count_var</th>\n",
              "      <th>sentences_per_post</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5138</th>\n",
              "      <td>you know what you can do show him a more accur...</td>\n",
              "      <td>28.420000</td>\n",
              "      <td>146.166939</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6148</th>\n",
              "      <td>youve gotta be starving youve gotta be starvin...</td>\n",
              "      <td>14.578947</td>\n",
              "      <td>141.331437</td>\n",
              "      <td>1.973684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5343</th>\n",
              "      <td>god dangit now the song listen to your heart i...</td>\n",
              "      <td>22.200000</td>\n",
              "      <td>171.102041</td>\n",
              "      <td>2.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>nomadleviathan yeah it can take this form as w...</td>\n",
              "      <td>31.652174</td>\n",
              "      <td>61.654106</td>\n",
              "      <td>3.021739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1932</th>\n",
              "      <td>well he didnt appear toxic when i met him a bi...</td>\n",
              "      <td>31.638889</td>\n",
              "      <td>93.837302</td>\n",
              "      <td>2.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4055</th>\n",
              "      <td>i ticked volunteering as one of my answers so ...</td>\n",
              "      <td>28.437500</td>\n",
              "      <td>149.953457</td>\n",
              "      <td>2.291667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4927</th>\n",
              "      <td>im way too forgiving i am not a door slammer i...</td>\n",
              "      <td>33.240000</td>\n",
              "      <td>97.328980</td>\n",
              "      <td>2.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6811</th>\n",
              "      <td>also ive had this bizarre in depth fascination...</td>\n",
              "      <td>33.857143</td>\n",
              "      <td>56.541667</td>\n",
              "      <td>2.653061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>coulda been better hello and welcome from a fe...</td>\n",
              "      <td>24.180000</td>\n",
              "      <td>188.640408</td>\n",
              "      <td>3.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1753</th>\n",
              "      <td>they are usually the kind of girls who you can...</td>\n",
              "      <td>22.687500</td>\n",
              "      <td>220.942819</td>\n",
              "      <td>2.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6160</th>\n",
              "      <td>no emotional guilt here over anything at all i...</td>\n",
              "      <td>23.673913</td>\n",
              "      <td>143.735749</td>\n",
              "      <td>3.043478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6093</th>\n",
              "      <td>so strange that i relate to this entirely i ha...</td>\n",
              "      <td>30.480000</td>\n",
              "      <td>98.744490</td>\n",
              "      <td>2.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3844</th>\n",
              "      <td>then i guess maybe engineering has more of the...</td>\n",
              "      <td>30.560000</td>\n",
              "      <td>88.169796</td>\n",
              "      <td>2.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6827</th>\n",
              "      <td>im pretty sure it has something to do with the...</td>\n",
              "      <td>29.765957</td>\n",
              "      <td>92.052729</td>\n",
              "      <td>2.744681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2234</th>\n",
              "      <td>its freaky how much i can relate to this lol i...</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>151.928571</td>\n",
              "      <td>2.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5190</th>\n",
              "      <td>hey i dont know it had better hurry up get out...</td>\n",
              "      <td>28.920000</td>\n",
              "      <td>112.973061</td>\n",
              "      <td>2.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1394</th>\n",
              "      <td>is this true for other women what about you i...</td>\n",
              "      <td>16.469388</td>\n",
              "      <td>102.504252</td>\n",
              "      <td>2.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8278</th>\n",
              "      <td>sometimes his explanations come out convoluted...</td>\n",
              "      <td>32.787234</td>\n",
              "      <td>64.345051</td>\n",
              "      <td>2.680851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3584</th>\n",
              "      <td>i took a different big test that goes a little...</td>\n",
              "      <td>25.510638</td>\n",
              "      <td>162.429232</td>\n",
              "      <td>1.978723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3526</th>\n",
              "      <td>dear classmates just a few its not cool to sit...</td>\n",
              "      <td>26.416667</td>\n",
              "      <td>161.907801</td>\n",
              "      <td>2.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>definitely conflict too unreasonable loudness ...</td>\n",
              "      <td>31.857143</td>\n",
              "      <td>96.375000</td>\n",
              "      <td>2.693878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>since i hardly have any unique talents that ac...</td>\n",
              "      <td>19.220000</td>\n",
              "      <td>148.052653</td>\n",
              "      <td>1.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6884</th>\n",
              "      <td>all introverts personalized activities for any...</td>\n",
              "      <td>27.340000</td>\n",
              "      <td>145.616735</td>\n",
              "      <td>2.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6149</th>\n",
              "      <td>one of my few love poems love the ghost beat t...</td>\n",
              "      <td>29.940000</td>\n",
              "      <td>97.935102</td>\n",
              "      <td>2.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5988</th>\n",
              "      <td>completing my fifteenth post so i can start a ...</td>\n",
              "      <td>21.140000</td>\n",
              "      <td>140.857551</td>\n",
              "      <td>1.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>i feel like a rookie professional sports playe...</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>118.408163</td>\n",
              "      <td>2.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7613</th>\n",
              "      <td>as i scanned through all the pictures i saw yo...</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>117.510204</td>\n",
              "      <td>2.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8084</th>\n",
              "      <td>the love of my life &amp; one true happiness left ...</td>\n",
              "      <td>19.200000</td>\n",
              "      <td>237.224490</td>\n",
              "      <td>1.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8017</th>\n",
              "      <td>another holy shit are we being trolled or what...</td>\n",
              "      <td>26.340426</td>\n",
              "      <td>160.316374</td>\n",
              "      <td>2.297872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5467</th>\n",
              "      <td>im going to be boring and say spirited away an...</td>\n",
              "      <td>23.500000</td>\n",
              "      <td>151.404255</td>\n",
              "      <td>2.354167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>samantha theodore twombly amy  reference arche...</td>\n",
              "      <td>21.065217</td>\n",
              "      <td>170.062319</td>\n",
              "      <td>1.913043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>it happens to me i feel compelled to help peop...</td>\n",
              "      <td>29.240000</td>\n",
              "      <td>142.716735</td>\n",
              "      <td>2.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3459</th>\n",
              "      <td>and kanye is s to the maximum sent from my sm ...</td>\n",
              "      <td>27.640000</td>\n",
              "      <td>152.071837</td>\n",
              "      <td>2.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3307</th>\n",
              "      <td>thanks guys admittedly ive been trained throug...</td>\n",
              "      <td>30.877551</td>\n",
              "      <td>80.109694</td>\n",
              "      <td>2.591837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5399</th>\n",
              "      <td>try going without a hug for months sad  i thin...</td>\n",
              "      <td>25.489796</td>\n",
              "      <td>171.505102</td>\n",
              "      <td>2.367347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>knowledge and spare change branchmonkey aw tha...</td>\n",
              "      <td>26.129630</td>\n",
              "      <td>183.586653</td>\n",
              "      <td>2.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8425</th>\n",
              "      <td>ive paid off my hundred dollar batarang editio...</td>\n",
              "      <td>27.408163</td>\n",
              "      <td>113.246599</td>\n",
              "      <td>2.040816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8671</th>\n",
              "      <td>soif this thread already exists someplace else...</td>\n",
              "      <td>27.160000</td>\n",
              "      <td>128.177959</td>\n",
              "      <td>2.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5356</th>\n",
              "      <td>i sent you my heart and you didnt recoil in fa...</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>92.051020</td>\n",
              "      <td>2.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6620</th>\n",
              "      <td>i think i`m facing a burnout of some kind and ...</td>\n",
              "      <td>25.520000</td>\n",
              "      <td>174.295510</td>\n",
              "      <td>1.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4250</th>\n",
              "      <td>veggie lo mein with rice noodles and a homemad...</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>95.795918</td>\n",
              "      <td>2.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>well hello im horrid with managing passwords a...</td>\n",
              "      <td>28.220000</td>\n",
              "      <td>120.542449</td>\n",
              "      <td>3.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>well thats exactly what i had in mind sounds a...</td>\n",
              "      <td>23.020408</td>\n",
              "      <td>169.895408</td>\n",
              "      <td>2.816327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7413</th>\n",
              "      <td>dont do it even reuburns the said that too the...</td>\n",
              "      <td>31.020000</td>\n",
              "      <td>72.264898</td>\n",
              "      <td>2.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7413</th>\n",
              "      <td>dont do it even reuburns the said that too the...</td>\n",
              "      <td>31.020000</td>\n",
              "      <td>72.264898</td>\n",
              "      <td>2.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2375</th>\n",
              "      <td>first of all what she feels is totally normal ...</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>37.428571</td>\n",
              "      <td>2.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185</th>\n",
              "      <td>what do you all think of lily potter i like to...</td>\n",
              "      <td>30.700000</td>\n",
              "      <td>129.275510</td>\n",
              "      <td>2.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2561</th>\n",
              "      <td>i find this with my partner who is an weve bee...</td>\n",
              "      <td>34.460000</td>\n",
              "      <td>63.518776</td>\n",
              "      <td>2.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4236</th>\n",
              "      <td>yayy that was unexpected laughing bring it on ...</td>\n",
              "      <td>29.704545</td>\n",
              "      <td>110.306025</td>\n",
              "      <td>2.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7969</th>\n",
              "      <td>as a personal challenge i like to pick up char...</td>\n",
              "      <td>32.580000</td>\n",
              "      <td>76.575102</td>\n",
              "      <td>2.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7380</th>\n",
              "      <td>a lot of these are really true what would defi...</td>\n",
              "      <td>27.958333</td>\n",
              "      <td>151.147163</td>\n",
              "      <td>2.145833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6899</th>\n",
              "      <td>hi im an and am married to an so i have some c...</td>\n",
              "      <td>33.900000</td>\n",
              "      <td>57.846939</td>\n",
              "      <td>2.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8360</th>\n",
              "      <td>s are pretty great in general good listeners g...</td>\n",
              "      <td>25.125000</td>\n",
              "      <td>152.367021</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>so if a christian is a follower of jesus what ...</td>\n",
              "      <td>16.804348</td>\n",
              "      <td>165.271981</td>\n",
              "      <td>1.869565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5040</th>\n",
              "      <td>im definitely a band nerd lol section leader t...</td>\n",
              "      <td>18.700000</td>\n",
              "      <td>153.357143</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>standardlawyer please so i couldnt find the ar...</td>\n",
              "      <td>20.740000</td>\n",
              "      <td>178.441224</td>\n",
              "      <td>2.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>hi guys i know the whole which type is the mos...</td>\n",
              "      <td>31.420000</td>\n",
              "      <td>89.554694</td>\n",
              "      <td>2.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>make sure you delete the search history tongue...</td>\n",
              "      <td>23.122449</td>\n",
              "      <td>167.109694</td>\n",
              "      <td>2.326531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6511</th>\n",
              "      <td>hi dupin im and from new hampshire  thank you ...</td>\n",
              "      <td>32.900000</td>\n",
              "      <td>126.908163</td>\n",
              "      <td>2.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5350</th>\n",
              "      <td>question if you are familiar with the enneagra...</td>\n",
              "      <td>30.280000</td>\n",
              "      <td>112.205714</td>\n",
              "      <td>3.420000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10708 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     posts  words_per_post  \\\n",
              "user_id                                                                      \n",
              "5138     you know what you can do show him a more accur...       28.420000   \n",
              "6148     youve gotta be starving youve gotta be starvin...       14.578947   \n",
              "5343     god dangit now the song listen to your heart i...       22.200000   \n",
              "3530     nomadleviathan yeah it can take this form as w...       31.652174   \n",
              "1932     well he didnt appear toxic when i met him a bi...       31.638889   \n",
              "4055     i ticked volunteering as one of my answers so ...       28.437500   \n",
              "4927     im way too forgiving i am not a door slammer i...       33.240000   \n",
              "6811     also ive had this bizarre in depth fascination...       33.857143   \n",
              "1091     coulda been better hello and welcome from a fe...       24.180000   \n",
              "1753     they are usually the kind of girls who you can...       22.687500   \n",
              "6160     no emotional guilt here over anything at all i...       23.673913   \n",
              "6093     so strange that i relate to this entirely i ha...       30.480000   \n",
              "3844     then i guess maybe engineering has more of the...       30.560000   \n",
              "6827     im pretty sure it has something to do with the...       29.765957   \n",
              "2234     its freaky how much i can relate to this lol i...       30.500000   \n",
              "5190     hey i dont know it had better hurry up get out...       28.920000   \n",
              "1394      is this true for other women what about you i...       16.469388   \n",
              "8278     sometimes his explanations come out convoluted...       32.787234   \n",
              "3584     i took a different big test that goes a little...       25.510638   \n",
              "3526     dear classmates just a few its not cool to sit...       26.416667   \n",
              "3397     definitely conflict too unreasonable loudness ...       31.857143   \n",
              "545      since i hardly have any unique talents that ac...       19.220000   \n",
              "6884     all introverts personalized activities for any...       27.340000   \n",
              "6149     one of my few love poems love the ghost beat t...       29.940000   \n",
              "5988     completing my fifteenth post so i can start a ...       21.140000   \n",
              "4595     i feel like a rookie professional sports playe...       22.600000   \n",
              "7613     as i scanned through all the pictures i saw yo...       30.600000   \n",
              "8084     the love of my life & one true happiness left ...       19.200000   \n",
              "8017     another holy shit are we being trolled or what...       26.340426   \n",
              "5467     im going to be boring and say spirited away an...       23.500000   \n",
              "...                                                    ...             ...   \n",
              "806      samantha theodore twombly amy  reference arche...       21.065217   \n",
              "314      it happens to me i feel compelled to help peop...       29.240000   \n",
              "3459     and kanye is s to the maximum sent from my sm ...       27.640000   \n",
              "3307     thanks guys admittedly ive been trained throug...       30.877551   \n",
              "5399     try going without a hug for months sad  i thin...       25.489796   \n",
              "2929     knowledge and spare change branchmonkey aw tha...       26.129630   \n",
              "8425     ive paid off my hundred dollar batarang editio...       27.408163   \n",
              "8671     soif this thread already exists someplace else...       27.160000   \n",
              "5356     i sent you my heart and you didnt recoil in fa...       31.900000   \n",
              "6620     i think i`m facing a burnout of some kind and ...       25.520000   \n",
              "4250     veggie lo mein with rice noodles and a homemad...       31.000000   \n",
              "1502     well hello im horrid with managing passwords a...       28.220000   \n",
              "5226     well thats exactly what i had in mind sounds a...       23.020408   \n",
              "7413     dont do it even reuburns the said that too the...       31.020000   \n",
              "7413     dont do it even reuburns the said that too the...       31.020000   \n",
              "2375     first of all what she feels is totally normal ...       35.000000   \n",
              "5185     what do you all think of lily potter i like to...       30.700000   \n",
              "2561     i find this with my partner who is an weve bee...       34.460000   \n",
              "4236     yayy that was unexpected laughing bring it on ...       29.704545   \n",
              "7969     as a personal challenge i like to pick up char...       32.580000   \n",
              "7380     a lot of these are really true what would defi...       27.958333   \n",
              "6899     hi im an and am married to an so i have some c...       33.900000   \n",
              "8360     s are pretty great in general good listeners g...       25.125000   \n",
              "5165     so if a christian is a follower of jesus what ...       16.804348   \n",
              "5040     im definitely a band nerd lol section leader t...       18.700000   \n",
              "7239     standardlawyer please so i couldnt find the ar...       20.740000   \n",
              "281      hi guys i know the whole which type is the mos...       31.420000   \n",
              "2398     make sure you delete the search history tongue...       23.122449   \n",
              "6511     hi dupin im and from new hampshire  thank you ...       32.900000   \n",
              "5350     question if you are familiar with the enneagra...       30.280000   \n",
              "\n",
              "         words_count_var  sentences_per_post  \n",
              "user_id                                       \n",
              "5138          146.166939            3.000000  \n",
              "6148          141.331437            1.973684  \n",
              "5343          171.102041            2.020000  \n",
              "3530           61.654106            3.021739  \n",
              "1932           93.837302            2.916667  \n",
              "4055          149.953457            2.291667  \n",
              "4927           97.328980            2.900000  \n",
              "6811           56.541667            2.653061  \n",
              "1091          188.640408            3.080000  \n",
              "1753          220.942819            2.833333  \n",
              "6160          143.735749            3.043478  \n",
              "6093           98.744490            2.860000  \n",
              "3844           88.169796            2.900000  \n",
              "6827           92.052729            2.744681  \n",
              "2234          151.928571            2.620000  \n",
              "5190          112.973061            2.960000  \n",
              "1394          102.504252            2.530612  \n",
              "8278           64.345051            2.680851  \n",
              "3584          162.429232            1.978723  \n",
              "3526          161.907801            2.645833  \n",
              "3397           96.375000            2.693878  \n",
              "545           148.052653            1.960000  \n",
              "6884          145.616735            2.800000  \n",
              "6149           97.935102            2.880000  \n",
              "5988          140.857551            1.920000  \n",
              "4595          118.408163            2.400000  \n",
              "7613          117.510204            2.760000  \n",
              "8084          237.224490            1.940000  \n",
              "8017          160.316374            2.297872  \n",
              "5467          151.404255            2.354167  \n",
              "...                  ...                 ...  \n",
              "806           170.062319            1.913043  \n",
              "314           142.716735            2.900000  \n",
              "3459          152.071837            2.220000  \n",
              "3307           80.109694            2.591837  \n",
              "5399          171.505102            2.367347  \n",
              "2929          183.586653            2.444444  \n",
              "8425          113.246599            2.040816  \n",
              "8671          128.177959            2.860000  \n",
              "5356           92.051020            2.740000  \n",
              "6620          174.295510            1.980000  \n",
              "4250           95.795918            2.260000  \n",
              "1502          120.542449            3.660000  \n",
              "5226          169.895408            2.816327  \n",
              "7413           72.264898            2.560000  \n",
              "7413           72.264898            2.560000  \n",
              "2375           37.428571            2.580000  \n",
              "5185          129.275510            2.360000  \n",
              "2561           63.518776            2.520000  \n",
              "4236          110.306025            2.636364  \n",
              "7969           76.575102            2.660000  \n",
              "7380          151.147163            2.145833  \n",
              "6899           57.846939            2.980000  \n",
              "8360          152.367021            2.000000  \n",
              "5165          165.271981            1.869565  \n",
              "5040          153.357143            2.300000  \n",
              "7239          178.441224            2.660000  \n",
              "281            89.554694            2.360000  \n",
              "2398          167.109694            2.326531  \n",
              "6511          126.908163            2.740000  \n",
              "5350          112.205714            3.420000  \n",
              "\n",
              "[10708 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MzWxwqsCLSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text\n",
        "\n",
        "TOP_K = 10000\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 5000\n",
        "\n",
        "def sequence_vectorize(train_texts, val_texts):\n",
        "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "    max_length = len(max(x_train, key=len))\n",
        "    if max_length > MAX_SEQUENCE_LENGTH:\n",
        "        max_length = MAX_SEQUENCE_LENGTH\n",
        "\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
        "\n",
        "    return x_train, x_val, tokenizer.word_index, max_length, TOP_K, [key for key, value in tokenizer.word_index.items() if value <= TOP_K]\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KYVYN3QC-WR",
        "colab_type": "code",
        "outputId": "6b9d9490-7b8e-4495-a2f1-aa943bf964af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    \n",
        "def remove_stop_words_and_lemmatize(data):\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  res = []\n",
        "  for a in data:\n",
        "    input_str = word_tokenize(a)\n",
        "    temp_str = \"\"\n",
        "    for word in input_str:\n",
        "      if word in stop_words:\n",
        "        continue\n",
        "      temp_str += stemmer.stem(lemmatizer.lemmatize(word))\n",
        "      temp_str += lemmatizer.lemmatize(word)\n",
        "      temp_str += \" \"\n",
        "    temp_str = temp_str[:-1]\n",
        "    res.append(temp_str)\n",
        "  return res\n",
        "\n",
        "x_train, x_val = X_train.posts.values, X_test.posts.values\n",
        "x_train = remove_stop_words_and_lemmatize(x_train)\n",
        "x_val = remove_stop_words_and_lemmatize(x_val)\n",
        "\n",
        "x_train, x_val, word_index, max_length, vocab_size, all_words = sequence_vectorize(x_train, x_val)\n",
        "num_features = min(len(word_index) + 1, TOP_K)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiyrTF8MVwrK",
        "colab_type": "code",
        "outputId": "98186d07-2c35-46f6-caa3-dcb6191fd767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "def RNN():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_features, output_dim=64 , input_length=max_length))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(LSTM(16))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "model = RNN()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_test), epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10708 samples, validate on 1735 samples\n",
            "Epoch 1/3\n",
            "10708/10708 [==============================] - 118s 11ms/step - loss: 0.6891 - acc: 0.5328 - val_loss: 0.6181 - val_acc: 0.7637\n",
            "Epoch 2/3\n",
            "10708/10708 [==============================] - 117s 11ms/step - loss: 0.5320 - acc: 0.7449 - val_loss: 0.5771 - val_acc: 0.7228\n",
            "Epoch 3/3\n",
            "10708/10708 [==============================] - 117s 11ms/step - loss: 0.3176 - acc: 0.8765 - val_loss: 0.7406 - val_acc: 0.6709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b902584a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TUkTEMyuoPXg",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_val)\n",
        "y_pred = [1 if a > 0.5 else 0 for a in y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l3WnvfDQoPXk",
        "outputId": "33a2e2f7-f94e-431e-abaa-8c6cdfff27dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.42      0.38       413\n",
            "           1       0.81      0.75      0.78      1322\n",
            "\n",
            "   micro avg       0.67      0.67      0.67      1735\n",
            "   macro avg       0.58      0.59      0.58      1735\n",
            "weighted avg       0.70      0.67      0.68      1735\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[175, 238],\n",
              "       [333, 989]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LOmt_F2toPXn",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNpjei9JZALD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(y_train.sum() + y_test.sum()) / (len(y_train) + len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}